---
title: Definition of Ready and Done
weight: 3
---

# <%= current_page.data.title %>

<div id="main-content" class="wiki-content">
                           
        <p>A more comprehensive version of Definition of Ready and Done can be found here:&nbsp;<a href="/confluence/display/PMOR/Definition+of+Ready+and+Done">Definition of Ready and Done</a>. This page focuses purely on the QA piece.</p><h3 id="DefinitionofReadyandDoneQA-DefinitionofReady"><span class="handy-header aui-icon aui-icon-small aui-iconfont-link" title="Copy link"></span><strong>Definition of Ready</strong></h3><p>Following the <em>backlog refinement</em>&nbsp;session and prior to the <em>planning &amp; estimation</em> session the QA should ensure the following is completed to meet the Definition of Ready for a Story:</p><ul><li><strong>Acceptance test criteria</strong> have been written and discussed (with at minimum) the BA and PO and preferably a Dev as well.</li><li>The QA has analysed what level of test coverage is required for the Story:<ul><li><strong>Unit/component</strong> test coverage (Mocha/Chai; Junit etc)</li><li><strong>Integration</strong> and <strong>contract</strong> testing coverage (RestAssured; Spring) - Do you integrate with any new services / APIs?&nbsp; Do you need to update any stale data?</li><li><strong>Functional automation</strong> coverage (Codecept/Protractor). What coverage will the automation test provide?</li><li><strong>Cross browser</strong> – Do you need to extend the cross browser tests or add more browsers/browser versions to the suite?</li><li><strong>Performance</strong> – Do you need to extend the in-sprint performance test scenarios? Is any formal performance testing required?</li><li><strong>Accessibility</strong> - Beyond Pa11y is there a requirement to run any further accessibility tests via assistive technology tools or additional w3c compliance checkers?</li><li><strong>Manual testing</strong> - What percentage of testing needs to be conducted manually through exploratory or scripted testing?</li><li><strong>Manual Integration</strong>&nbsp;<strong>testing</strong>&nbsp;- Are your changes going to interact with any upstream/downstream systems? Consider planning &amp; scripting requirements outside your system boundaries.</li><li><strong>Devices</strong> - What level of device testing is required? Do you need to test with Sauce Labs, Responsive Web Design checkers/emulators or with real devices?</li><li><strong>Security</strong> - Will the daily OWASP check be adequate or is more detailed security testing required using tools such as Burpsuite and BlackDuck? Is an ITHC required?</li><li><strong>UAT </strong>and<strong> BAT</strong> - is there a requirement for this Story to be story tested or form part of an e2e scenario test with users (via internal or lab sessions) or with business stakeholders?</li><li><strong>Reporting</strong>&nbsp;- &nbsp;Does it require any additional reporting to be generated (i.e. via Jenkins)</li><li><strong>Test Harness availability - </strong>If the story is dependant on Common components, check whether a test harness is required/available for your story to integrate with CC&nbsp;</li></ul></li></ul><h3 id="DefinitionofReadyandDoneQA-DuringthedevelopmentprocesstheQAshould:"><span class="handy-header aui-icon aui-icon-small aui-iconfont-link" title="Copy link"></span><strong>During the development process the QA should:</strong></h3><ul><li>Pre-story huddle with a BA/PO and the developer picking up the Story.</li><li>Post story huddle with a BA/PO and the developer checking in the code for the Story.</li><li>View all Pull Requests where possible checking for automated test coverage.</li></ul><h3 id="DefinitionofReadyandDoneQA-DefinitionofDone"><span class="handy-header aui-icon aui-icon-small aui-iconfont-link" title="Copy link"></span><strong>Definition of Done</strong></h3><p>In order for a Story to be considered complete the QA should check the following with the team prior to sign off of the story by a PO:</p><ul><li>Meets unit test code coverage (&gt;80%) - via SonarQube</li><li>All acceptance criteria have been tested.</li><li>All automated tests identified as part of the required test coverage have been created, executed and passed (via Jenkins).</li><li>All required manual tests have been executed and passed.&nbsp;</li><li>All manual Zephyr test suites have been updated (Regression suite and/or Project specific Exploratory suite)</li><li>Ensure sign off with a PO.</li></ul><p><br></p><p><strong>Reference:</strong></p><p><a href="https://tools.hmcts.net/confluence/display/PMOR/Definition+of+Ready+and+Done" rel="nofollow">https://tools.hmcts.net/confluence/display/PMOR/Definition+of+Ready+and+Done</a></p><p><a href="https://tools.hmcts.net/confluence/display/RQA/Reform+-+High+Level+Test+Strategy#QA%2520activities" rel="nofollow">QA Activities</a></p><p><a href="https://www.agilealliance.org/glossary/three-amigos/" class="external-link" rel="nofollow">https://www.agilealliance.org/glossary/three-amigos/</a></p><p><br></p>

                
        
    
        </div>
